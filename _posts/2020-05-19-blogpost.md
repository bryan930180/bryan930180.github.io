---
layout: post
title: A SARIMA model for influenza forecasting
subtitle: Time Series Project
image: /assets/img/Flu_SARIMA/Influenza.jpg
share-img: /assets/img/Flu_SARIMA/Influenza.jpg
published: true
---

### Introduction
In light of the recent COVID-19 outbreak, there has been an increased interest in virology and infectious disease. I decided to examine the CDC influenza mortality dataset that is publicly available and analyze the seasonality of the common flu. Every year, countries closely monitor the virus strains and predict the optimal time in which to develop and deliver vaccines at the right time. Although it is common knowledge that morbidity and mortality due to the flu increases during the winter, having an accurate forecasting model may better inform vaccine distribution decisions. In this project, we develop a SARIMA model to analyze the trend and seasonal periodicity of influenza mortality and evaluate the accuracy of the developed SARIMA model.

### Data visualization, cleaning, and transformation
One major goal of this project is to have the data resolution that other models don’t have. Therefore, I decided to look for weekly data instead of monthly data, which is the more common alternative. The data is obtained from the CDC weekly influenza report, which include data from September 29th, 2013 to April 12th, 2020. (URL in title page) I decided to use all of the data since only less than 7 52-week periods were recorded. This would make sure I have enough training for the seasonal component of the SARIMA model. The data was not scaled because the number of deaths per week lie well between 0 and 1700. Although there were no missing data, I decided to remove the data point at 53 weeks in the year 2014 to maintain a constant 52-week period for subsequent analysis. This yields a total of 341 data points. Although this would create some bias in the estimation, the width of the peaks displayed in figure 1a are relatively large relative to one week.

![](/assets/img/Flu_SARIMA/figure_1.png)
Figure 1: Data visualization of the number of influenza deaths from September 29th, 2013 to April 12th, 2020 a. Original count of Influenza Deaths b. Data after a square root transform, and c. Data log transform.

In figure 1a, we observe a clear seasonality of the data and a peak around the beginning of every year. The data does not appear to have an increasing or decreasing trend over time. For most years, we have the maximum influenza deaths of around 600 cases. Although year 2015 and 2018 appear to have a larger number of influenza deaths, we will not consider the values from those two years as an outlier, as it could be a stochastic seasonal component of the data. Upon more detailed examination, we observe that the peaks, such as that of 2016, don’t line up exactly annually. This could be an issue later when we define the period to be 52 weeks. The data is skewed towards lower values and does not resemble a white-noise process. Knowing the structure of the data, variance stabilization is performed to better model the time series. The square-root and log Box-Jenkins transformations of the data are also plotted above. (Figure 1b, 1c) After the log-transformation, although there was an increase in noise at the troughs relative to the new scale, the process better resembles a Gaussian and mean-reverting process. The periodicity is preserved as we transform the data and now we aim to decompose the data into its trend, seasonal, and random components.

### Trend Identification
 
![](/assets/img/Flu_SARIMA/figure_2.png)
Figure 2: Classical decomposition of the number of influenza death, including the a. original data, b. stochastic random noise component c. the seasonal component d. the trend component.

Initially, moving average smoothing was performed (not shown). However, since the influenza deaths over time does not have a clear trend, the moving average transformation merely decreased the intensity of the peaks. Therefore, I performed a classical decomposition of the data instead. In figure 2, the seasonal component is largely extracted from the data but the remainder still does not appear to be white noise. I tested this observation using the auto.arima function with max.q = 0 (not shown) which showed an AR (2) relation. This confirms our observation that the random component does not appear to be white noise. Most importantly, the trend appears to be approximately stepwise, indicating that it could just be a stochastic seasonal component, instead of a trend. That is, the additive model of X_t=s_t+m_t+Y_t with s_t and m_t deterministic is not necessarily true. Since we do not observe a trend other than the stepwise trend, we move on to a SARIMA model to address the stochasticity of seasonality.
 
![](/assets/img/Flu_SARIMA/figure_3.png)
Figure 3: a. Log transform of influenzas deaths after differencing at lag = (1, 12) b. ACF and c. PACF of influenza deaths after log-transform and differencing at lag = (1, 12).
SARIMA model fitting and parameter estimation

To begin, I first performed differencing at a lag of 12 and lag of 1 on the log-transformed data to eliminate the seasonal trend, so ACF and PACF can be properly analyzed. (Figure 4a) Then, I tested for a unit-root using both the Augmented Dicky Fuller and Kwiatkowski-Phillips-Schmidt-Shin test to make sure further differencing is not needed. (not shown) I then proceed to plot the ACF and PACF of the differenced data. After log-transform and differencing, the data look much more like a white noise. That is, the bands do not fluctuate like a sinusoidal function. However, a concentration of noise is still seen at the end of every year. This seasonality would probably be addressed with the SARIMA model since the seasonality left appear to be stochastic. Auto.arima and the armasubset function could not be ran because the period is set at 52 weeks. This means that there would be a large combination of differencing, AR, and MA coefficients to be tested and it is too computationally expensive for R. Instead of averaging the data at given timepoints, which would decrease the data resolution, I decided to continue with my analysis manually. In the ACF plot, we observe there could be significant ACF at lag 1-5, 52-56, and 102. In the PACF plot, we observe there could be significant PACF at lag 1-4 and 51-52. I then decided to perform subset ARIMA model selection by overfitting the model, then cut down the number of parameters by examining the coefficients and its standard error.

I started with the SARIMA (5,1,2)  (3,1,1)12 model and performed a stepwise backwards selection on the SARIMA coefficients. That is, I removed the coefficient with the lowest test statistic until all coefficients are significant, with test statistics Coefficeint/(SE(Coefficient)) greater than 1.96 when derive the adequate model. In order, I removed the coefficients for AR5(φ5), SMA1(Θ1), AR1(φ1), MA2(θ2), AR3(φ3), AR4(φ4) to arrive at a SARIMA (2,1,1)  (3,1,0)12 model. This will be used as the final model for the ARIMA forecast. The coefficients of the final model are displayed in table 1.

Table 1: SARIMA coefficients and standard errors
![](/assets/img/Flu_SARIMA/table_1.png)

### Comparison with non-ARIMA Forecasting

Table 2: Error measures for Holt-Winters forecasting and three SARIMA models
![](/assets/img/Flu_SARIMA/table_2.png)

Now, we compare our derived SARIMA model with the Holt-Winters forecasting method, a non-ARIMA forecasting method. I divided the first 289 to the training data and the last 52 weeks (a year) to the testing data. I then calculated three different error measures to compare the models (RMSE, MAE, and MAPE). I expected the SARIMA model to be much more accurate than the Holt-Winters forecasting method because Holt-Winters is based on a double exponential smoothing method that regresses on the previous values. This method would usually be useful for short-term, trend-based forecast, but not for a forecast of a seasonal phenomenon. For SARIMA models, I also included the last three models in the step-wise backward selection for comparison. The observed errors clearly indicate that SARIMA forecasts have a much better performance than the Holt-Winter forecast. (Table 1) Although I wanted to compare the AICc’s between the SARIMA models to choose the best one, AICc values were not outputted by R because the period of 52 overwhelmed the memory when calculating the MLE estimator. However, since the other error measures of the SARIMA model were comparable, we settle with the final model because it has the fewest parameters. The SARIMA forecast is displayed in figure 5. The 95% confidence interval nicely captures most of the previous peak heights and the predictions in the trough of the curve are very well-fitted.
 
![](/assets/img/Flu_SARIMA/figure_4.png)
Figure 4: One year forecast with the final model (SARIMA (2,1,1) * (3,1,0)<sup>12</sup> AR (1) fixed) with 80% and 95% confidence interval.

![](/assets/img/Flu_SARIMA/figure_5.png)
Figure 5: Innovation analysis of the final model a. Standardized innovations b. ACF of residuals c. p-values for the Ljung-Box statistic d. Histogram of innovations e. QQ-plot of innovations.

Since the time series data are dependent, the plotted residuals above represent an analysis of the innovations. I confirmed that the residuals are not significantly different from white noise by the auto.arima function with max.q = 0 (not shown) and by the p-values for the Ljung-Box statistic, which all lie above 0.05. In both the histogram of innovations and the Q-Q plot we observe one outlier that has a much higher value than the predicted value. However, the rest of the data showed good predict capacity as the tails of the Q-Q plot does not deviate from the Q-Q line by much.

### Conclusion
This analysis demonstrates that a log-transformed SARIMA (2,1,1) * (3,1,0)<sup>12</sup> with fixed AR (1) model can be used to forecast the influenza mortality rate with the above specified parameters. We found that a parametric forecasting approach is better than non-parametric forecasting such as the Holt-winters for the present data. There appear to not be an increasing trend over time of influenza cases as vaccines are predeveloped every year. However, we should be cautious of specific shocks such as that in as in year 2015 and 2018 which could increase the number of cases. We also encourage the usage of weekly data to increase the data resolution and predictive capacity as seen from the present study.
